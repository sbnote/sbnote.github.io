{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 全连接层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 张量方式实现全连接层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tf.Tensor: shape=(2, 256), dtype=float32, numpy=\narray([[2.1130817 , 2.5407083 , 1.5744436 , 1.2214776 , 0.8052367 ,\n        0.8906957 , 0.        , 0.41892922, 0.        , 0.        ,\n        0.        , 0.        , 0.73324656, 1.4538964 , 1.6196946 ,\n        0.        , 2.0996134 , 0.        , 0.        , 0.        ,\n        0.        , 1.9851398 , 0.        , 1.2431812 , 2.0866807 ,\n        0.        , 0.79602885, 3.6555233 , 0.        , 0.        ,\n        0.        , 0.34293503, 2.1629255 , 2.3206582 , 0.        ,\n        0.        , 0.        , 1.2399703 , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        3.685226  , 0.        , 0.74559474, 0.        , 0.2405889 ,\n        0.2439518 , 0.9677445 , 0.        , 0.72200465, 3.2210338 ,\n        0.        , 0.        , 0.        , 1.6820909 , 0.        ,\n        0.19177568, 0.33097625, 0.        , 0.23417406, 2.9687614 ,\n        0.        , 0.6390914 , 2.608281  , 0.        , 0.83842504,\n        0.13012892, 0.        , 2.1018682 , 1.9333422 , 0.10335612,\n        0.        , 1.2511715 , 2.22904   , 0.46338847, 1.9902141 ,\n        3.0023146 , 1.903695  , 0.        , 0.        , 3.0801005 ,\n        0.29834652, 0.        , 0.03817627, 0.        , 0.        ,\n        0.9368671 , 0.        , 0.05496359, 0.        , 0.        ,\n        1.1400094 , 3.787441  , 2.8018703 , 1.1220343 , 0.        ,\n        0.        , 0.        , 0.7149988 , 0.        , 0.        ,\n        2.4986122 , 0.        , 0.71747243, 1.6598127 , 0.        ,\n        2.83474   , 1.5462344 , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 2.850819  ,\n        1.1806678 , 0.8294983 , 2.4163084 , 0.        , 0.        ,\n        0.41786635, 0.        , 0.        , 0.        , 2.3858638 ,\n        0.25422883, 0.        , 1.2134316 , 5.231696  , 3.7223463 ,\n        1.570873  , 0.        , 0.        , 0.        , 0.        ,\n        1.3495216 , 0.71557534, 0.        , 2.585768  , 0.        ,\n        0.        , 0.        , 0.30205047, 0.        , 0.        ,\n        0.        , 0.        , 0.26581234, 0.        , 0.9252719 ,\n        1.1103542 , 0.        , 0.9688741 , 1.5295655 , 0.        ,\n        0.        , 0.        , 4.193181  , 0.21035296, 4.348426  ,\n        0.        , 1.3615266 , 0.0544017 , 0.20699039, 0.        ,\n        0.21648228, 0.38094264, 0.        , 0.        , 0.        ,\n        1.2967145 , 0.        , 0.6376766 , 0.        , 1.2819343 ,\n        0.        , 3.7872403 , 0.        , 5.1223297 , 1.8620594 ,\n        3.9421024 , 0.        , 1.1245577 , 0.5002793 , 4.520059  ,\n        1.3776124 , 1.6551753 , 0.7690593 , 0.        , 1.817936  ,\n        0.        , 0.37478578, 2.4448473 , 0.        , 4.2684374 ,\n        0.        , 0.        , 3.1408386 , 1.3472059 , 0.        ,\n        2.4741385 , 0.21341032, 2.8918166 , 0.        , 1.1155475 ,\n        1.7249265 , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.8137909 , 0.        , 0.        , 0.        ,\n        1.9854759 , 0.37436703, 4.819314  , 0.        , 0.        ,\n        0.        , 2.4473553 , 0.        , 1.9685373 , 0.01283586,\n        1.5308868 , 1.6306325 , 2.4790266 , 1.1233974 , 2.9709253 ,\n        0.        , 1.3585625 , 0.7239573 , 0.        , 0.        ,\n        1.6920378 , 3.6838748 , 0.6321657 , 1.8364917 , 3.9952686 ,\n        1.0823123 , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.        ],\n       [0.        , 2.3080995 , 0.4069289 , 0.        , 0.        ,\n        2.6869845 , 1.7335907 , 0.7106055 , 0.        , 0.        ,\n        0.        , 0.        , 3.5220618 , 0.        , 0.        ,\n        3.1547818 , 0.        , 7.645525  , 0.        , 0.        ,\n        2.8234074 , 2.7673717 , 2.1419468 , 0.        , 0.        ,\n        0.        , 1.9996843 , 0.        , 1.3630719 , 1.1889457 ,\n        0.12482125, 3.2465198 , 0.        , 0.        , 0.        ,\n        0.        , 1.8836956 , 0.47870708, 0.        , 2.909039  ,\n        0.        , 0.95953107, 0.15955842, 0.        , 2.1909604 ,\n        1.4997845 , 0.0666548 , 1.5407572 , 0.        , 0.        ,\n        2.5436652 , 0.24521565, 0.        , 0.        , 0.2437383 ,\n        2.3753984 , 0.        , 1.7541808 , 0.        , 0.179551  ,\n        0.31920266, 1.4901857 , 0.27603972, 0.        , 0.37797207,\n        0.        , 0.        , 4.016098  , 0.2726025 , 0.        ,\n        0.        , 3.3495555 , 0.        , 1.9546902 , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.61309826, 0.        , 0.38120973, 0.        , 0.5778444 ,\n        0.        , 3.561776  , 0.        , 1.6151733 , 0.        ,\n        0.        , 4.8335733 , 0.        , 0.6357555 , 0.15224794,\n        0.        , 0.        , 2.4616628 , 0.        , 0.        ,\n        0.        , 0.        , 1.0288537 , 0.4468677 , 4.5805187 ,\n        0.        , 0.89123964, 0.        , 2.16116   , 0.        ,\n        0.        , 0.        , 0.        , 0.        , 3.8135242 ,\n        0.        , 0.        , 3.402405  , 2.3979235 , 0.        ,\n        0.24567205, 0.        , 0.        , 2.0610805 , 0.        ,\n        0.        , 0.        , 0.        , 0.6587604 , 2.3671155 ,\n        0.47878575, 0.        , 0.        , 0.        , 0.70112616,\n        0.        , 0.        , 1.1668725 , 1.0092502 , 0.        ,\n        0.        , 0.        , 2.4742384 , 0.        , 0.        ,\n        3.059957  , 1.5353633 , 0.        , 0.        , 0.        ,\n        0.        , 2.2971041 , 1.6391432 , 2.593725  , 0.        ,\n        0.        , 0.2506078 , 1.2113533 , 2.0561223 , 0.        ,\n        0.        , 6.3342867 , 0.05455089, 0.93349206, 0.7575867 ,\n        0.        , 5.4247885 , 0.73345673, 0.        , 0.49199146,\n        1.8460109 , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 1.7499512 , 0.        , 2.1614046 , 0.        ,\n        2.0614638 , 0.        , 0.        , 0.        , 2.4730506 ,\n        0.        , 0.9468185 , 3.8845303 , 0.        , 0.        ,\n        2.003882  , 0.9769447 , 3.8490438 , 0.        , 0.        ,\n        0.        , 0.        , 1.5266364 , 0.        , 0.        ,\n        4.602438  , 0.69083947, 0.        , 1.9802696 , 3.484735  ,\n        0.        , 0.        , 0.        , 0.        , 0.        ,\n        0.47827804, 2.4332528 , 0.        , 0.        , 3.5663302 ,\n        1.9175771 , 0.        , 0.        , 2.6818278 , 0.        ,\n        0.67832327, 0.        , 0.6006212 , 0.        , 0.        ,\n        2.627595  , 0.        , 0.        , 0.        , 0.        ,\n        0.        , 1.8232162 , 2.2735727 , 0.        , 0.        ,\n        0.        , 1.333364  , 0.3111925 , 1.6954224 , 3.9787538 ,\n        1.311094  , 0.82862526, 0.        , 1.5460277 , 0.23939997,\n        0.9687226 , 0.        , 0.05311751, 0.        , 3.4347684 ,\n        1.2207334 , 2.1712713 , 1.9767714 , 0.        , 0.        ,\n        0.        ]], dtype=float32)>"
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "x = tf.random.normal([2, 784])\n",
    "w1 = tf.Variable(tf.random.truncated_normal([784, 256], stddev=0.1))\n",
    "b1 = tf.Variable(tf.zeros([256]))\n",
    "o1 = tf.matmul(x, w1) + b1  # 线性变换\n",
    "o1 = tf.nn.relu(o1)  # 激活函数\n",
    "o1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 层方式实现全连接层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tf.Tensor: shape=(4, 512), dtype=float32, numpy=\narray([[0.        , 0.        , 0.        , ..., 1.9270766 , 0.        ,\n        0.        ],\n       [0.40866083, 0.        , 0.00809966, ..., 0.96293867, 0.42927146,\n        0.        ],\n       [0.        , 0.94622374, 0.23846656, ..., 0.        , 0.        ,\n        0.        ],\n       [1.1736572 , 1.9614882 , 0.7566602 , ..., 0.        , 0.        ,\n        0.        ]], dtype=float32)>"
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "x = tf.random.normal([4, 28*28])\n",
    "# 创建全连接层，指定输出节点数和激活函数\n",
    "fc= layers.Dense(512, activation=tf.nn.relu)\n",
    "# 通过fc类实例完成一次全连接层的计算，返回输出张量\n",
    "h1 = fc(x) \n",
    "h1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tf.Variable 'dense_1/kernel:0' shape=(784, 512) dtype=float32, numpy=\narray([[-0.00267227, -0.00282092, -0.00239151, ..., -0.02661727,\n         0.01147866,  0.06112941],\n       [ 0.04942616, -0.01818737, -0.06283382, ..., -0.03728904,\n         0.01348516, -0.05021691],\n       [-0.03163202,  0.06512868, -0.06132587, ...,  0.01436388,\n         0.02630632,  0.04413   ],\n       ...,\n       [-0.05554145,  0.05815712,  0.06551993, ...,  0.02543541,\n         0.00813754,  0.03728528],\n       [ 0.06328607, -0.04251216,  0.05813259, ...,  0.04935983,\n        -0.00627681,  0.04255246],\n       [-0.0233203 ,  0.0114582 ,  0.05262707, ..., -0.02605116,\n         0.02641326, -0.0292853 ]], dtype=float32)>"
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "# 获取Dense类的权值矩阵(权值张量W)\n",
    "fc.kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tf.Variable 'dense_1/bias:0' shape=(512,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0.], dtype=float32)>"
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "# 获取Dense类的偏置向量(偏置张量b)\n",
    "fc.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[<tf.Variable 'dense_1/kernel:0' shape=(784, 512) dtype=float32, numpy=\n array([[-0.00267227, -0.00282092, -0.00239151, ..., -0.02661727,\n          0.01147866,  0.06112941],\n        [ 0.04942616, -0.01818737, -0.06283382, ..., -0.03728904,\n          0.01348516, -0.05021691],\n        [-0.03163202,  0.06512868, -0.06132587, ...,  0.01436388,\n          0.02630632,  0.04413   ],\n        ...,\n        [-0.05554145,  0.05815712,  0.06551993, ...,  0.02543541,\n          0.00813754,  0.03728528],\n        [ 0.06328607, -0.04251216,  0.05813259, ...,  0.04935983,\n         -0.00627681,  0.04255246],\n        [-0.0233203 ,  0.0114582 ,  0.05262707, ..., -0.02605116,\n          0.02641326, -0.0292853 ]], dtype=float32)>,\n <tf.Variable 'dense_1/bias:0' shape=(512,) dtype=float32, numpy=\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0.], dtype=float32)>]"
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "# 获取网硌的所有待优化的张量参数列表，这里为W与b\n",
    "fc.trainable_variables\n",
    "\n",
    "# 获取网硌的所有不需要优化的张量参数列表\n",
    "# fc.non_trainable_variables\n",
    "\n",
    "# 获取所有参数列表，包含上面两者\n",
    "# fc.variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 张量方式实现神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tf.Tensor: shape=(4, 10), dtype=float32, numpy=\narray([[ 1.1116053 ,  0.3521677 , -3.0844083 , -0.4492345 ,  0.02406619,\n        -1.3208067 , -0.6864613 ,  1.3855261 ,  1.7404168 ,  1.0428905 ],\n       [ 1.3805524 , -0.9140596 , -3.5280728 , -1.7715396 , -0.5988324 ,\n        -1.8068151 , -0.80618507,  2.0329604 ,  1.9567118 ,  2.0659328 ],\n       [ 0.47052583,  0.44838816, -2.9082556 , -0.3542863 ,  0.14361091,\n        -0.89381874,  0.19095016,  0.7630715 ,  1.011778  ,  0.32503614],\n       [ 0.42761272, -0.3429447 , -1.0515895 , -0.23576887,  1.1572796 ,\n        -0.891214  , -0.93193775,  1.7463063 ,  0.45168707,  0.6394294 ]],\n      dtype=float32)>"
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "# 隐藏层1张量\n",
    "w1 = tf.Variable(tf.random.truncated_normal([784, 256], stddev=0.1))\n",
    "b1 = tf.Variable(tf.zeros([256]))\n",
    "\n",
    "# 隐藏层2张量\n",
    "w2 = tf.Variable(tf.random.truncated_normal([256, 128], stddev=0.1))\n",
    "b2 = tf.Variable(tf.zeros([128]))\n",
    "\n",
    "# 隐藏层3张量\n",
    "w3 = tf.Variable(tf.random.truncated_normal([128, 64], stddev=0.1))\n",
    "b3 = tf.Variable(tf.zeros([64]))\n",
    "\n",
    "# 输出层张量\n",
    "w4 = tf.Variable(tf.random.truncated_normal([64, 10], stddev=0.1))\n",
    "b4 = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "with tf.GradientTape() as tape:  # 梯度记录器\n",
    "    \n",
    "    # x: [b, 28*28]\n",
    "    # 隐藏层1前向计算，[b, 28*28] => [b, 256]\n",
    "    h1 = x@w1 + tf.broadcast_to(b1, [x.shape[0], 256])\n",
    "    h1 = tf.nn.relu(h1)\n",
    "\n",
    "    # 隐藏层2前向计算，[b, 256] => [b, 128]\n",
    "    h2 = h1@w2 + b2\n",
    "    h2 = tf.nn.relu(h2)\n",
    "\n",
    "    # 隐藏层3前向计算，[b, 128] => [b, 64]\n",
    "    h3 = h2@w3 + b3\n",
    "    h3 = tf.nn.relu(h3)\n",
    "\n",
    "    # 输出层前向计算，[b, 64] => [b, 10]\n",
    "    h4 = h3@w4 + b4\n",
    "\n",
    "h4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 层方式实现神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tf.Tensor: shape=(4, 28, 10), dtype=float32, numpy=\narray([[[-0.22507548, -0.3335405 ,  0.18823574, ..., -0.5659266 ,\n          0.14069253,  0.37929076],\n        [-0.07609231, -0.00811549,  0.19692197, ...,  0.15712182,\n         -0.00776023, -0.12052844],\n        [ 0.02161743,  0.01345335, -0.10942364, ...,  0.13579611,\n          0.10823181,  0.02750758],\n        ...,\n        [ 0.04026046,  0.2355012 ,  0.187748  , ..., -0.02560981,\n         -0.2025197 ,  0.1423256 ],\n        [-0.38276544, -0.41003254,  0.3780575 , ..., -0.64755726,\n          0.02313289,  0.5764718 ],\n        [-0.10360569, -0.10879605,  0.01929587, ...,  0.15574111,\n         -0.16224623,  0.03080903]],\n\n       [[-0.05802258,  0.10131766,  0.05638222, ...,  0.2514957 ,\n         -0.02359182, -0.07964724],\n        [-0.02173181,  0.20598564, -0.1934395 , ...,  0.1820691 ,\n         -0.11940306, -0.08369346],\n        [-0.11748201, -0.07291164,  0.10612024, ...,  0.0209903 ,\n          0.04095364,  0.0685025 ],\n        ...,\n        [-0.13147905, -0.01024492, -0.279504  , ...,  0.21856993,\n         -0.07228747,  0.40965155],\n        [-0.38172895,  0.00861502,  0.37398732, ...,  0.14165182,\n         -0.16527829,  0.13989681],\n        [-0.19339974,  0.2430938 , -0.3617861 , ...,  0.17793131,\n         -0.45848423, -0.24920371]],\n\n       [[-0.26087984, -0.16490671,  0.17241725, ..., -0.19517443,\n         -0.02525318,  0.0830394 ],\n        [-0.15314367, -0.13535249,  0.21778886, ..., -0.088843  ,\n          0.2174554 ,  0.16681488],\n        [-0.18668266,  0.07647568, -0.18585384, ..., -0.07566324,\n         -0.19211777, -0.14709248],\n        ...,\n        [ 0.00769261,  0.01379872, -0.06374861, ...,  0.16360675,\n          0.22379002,  0.05318676],\n        [-0.24611993, -0.03068137,  0.37368375, ...,  0.23309241,\n          0.00419625,  0.3487331 ],\n        [-0.06800089,  0.0922063 ,  0.05041837, ...,  0.34360805,\n         -0.1104539 ,  0.04552754]],\n\n       [[-0.16734412, -0.03037396,  0.10292359, ...,  0.09837908,\n         -0.07197034,  0.03136156],\n        [-0.2081445 ,  0.32430884, -0.35320795, ...,  0.2514805 ,\n         -0.23075515,  0.04502632],\n        [-0.4162502 ,  0.10315945, -0.05018219, ..., -0.04315152,\n         -0.351182  ,  0.06126426],\n        ...,\n        [ 0.24618013,  0.07147881,  0.18017745, ..., -0.06640539,\n          0.05452614,  0.2163036 ],\n        [-0.24131839,  0.15872602, -0.17705137, ...,  0.11705116,\n         -0.19760782, -0.08741356],\n        [-0.07623104, -0.10061658, -0.03864329, ...,  0.24894649,\n          0.20633185, -0.1350079 ]]], dtype=float32)>"
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "# 方式一\n",
    "# 隐藏层1\n",
    "fc1 = layers.Dense(256, activation=tf.nn.relu)\n",
    "# 隐藏层2\n",
    "fc2 = layers.Dense(128, activation=tf.nn.relu)\n",
    "# 隐藏层3\n",
    "fc3 = layers.Dense(64, activation=tf.nn.relu)\n",
    "# 隐藏层\n",
    "fc4 = layers.Dense(10, activation=None)\n",
    "\n",
    "x = tf.random.normal([4, 28, 28])\n",
    "h1 = fc1(x)  # 通过隐藏层1得到输出\n",
    "h2 = fc2(h1)  # 通过隐藏层2得到输出\n",
    "h3 = fc3(h2)  # 通过隐藏层3得到输出\n",
    "h4 = fc4(h3)  # 通过隐藏层4得到输出\n",
    "h4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tf.Tensor: shape=(4, 28, 10), dtype=float32, numpy=\narray([[[ 0.18359746,  0.2039048 , -0.30897447, ...,  0.01482356,\n         -0.34508723, -0.2538961 ],\n        [ 0.4427238 ,  0.34541032, -0.02827301, ...,  0.17581421,\n         -0.2104951 , -0.408833  ],\n        [ 0.2779747 , -0.26076353, -0.02709447, ...,  0.23210287,\n         -0.01470482, -0.10349187],\n        ...,\n        [ 0.72480965, -0.2286298 ,  0.01073468, ...,  0.24743868,\n         -0.18872644, -0.1235151 ],\n        [ 0.5499091 ,  0.1371733 , -0.16772051, ..., -0.09394544,\n         -0.1465384 ,  0.1599564 ],\n        [ 0.5045114 ,  0.00532827, -0.28540537, ...,  0.04006464,\n         -0.02622599, -0.27188185]],\n\n       [[ 0.34444043, -0.13919902, -0.16241826, ...,  0.31591365,\n         -0.27393425, -0.20587969],\n        [ 0.34367603, -0.20802435, -0.11203017, ...,  0.31192982,\n         -0.22424948, -0.06286694],\n        [ 0.294376  ,  0.20381735, -0.13052092, ...,  0.20241833,\n         -0.27694592, -0.08300988],\n        ...,\n        [ 0.35425004,  0.00169386, -0.23330903, ...,  0.28117532,\n         -0.33603832, -0.35112524],\n        [ 0.3364065 ,  0.11293084, -0.1815064 , ...,  0.07407906,\n         -0.4724179 , -0.466835  ],\n        [ 0.4578337 , -0.13980444, -0.18282746, ...,  0.46899888,\n         -0.23666772, -0.56423783]],\n\n       [[ 0.17043144,  0.00105917, -0.09118615, ...,  0.01671938,\n         -0.1704178 ,  0.21549663],\n        [ 0.44542152, -0.05023098, -0.3713626 , ...,  0.14456934,\n         -0.35957325, -0.19983737],\n        [ 0.35724992,  0.03680395, -0.05612152, ...,  0.33589536,\n         -0.33083874, -0.40743926],\n        ...,\n        [ 0.19799694, -0.1372166 , -0.22919804, ...,  0.20797911,\n         -0.1728164 , -0.02087834],\n        [ 0.3098834 , -0.04399908, -0.19407937, ...,  0.23181804,\n         -0.26908824, -0.1322863 ],\n        [ 0.30803353,  0.01109997, -0.29877603, ...,  0.15676732,\n         -0.24525484, -0.16053268]],\n\n       [[ 0.44603035,  0.11793263, -0.16878946, ...,  0.05914756,\n         -0.24434529, -0.13568531],\n        [ 0.5966331 ,  0.03634723, -0.22275275, ...,  0.33190086,\n         -0.56171817, -0.38363823],\n        [ 0.5378788 , -0.02089758, -0.03142088, ..., -0.10023807,\n         -0.1233294 ,  0.32444018],\n        ...,\n        [ 0.45653838, -0.47611398, -0.5261734 , ..., -0.06757904,\n          0.01461116,  0.20503496],\n        [ 0.59759504,  0.20165545, -0.14837031, ...,  0.317443  ,\n         -0.4098312 , -0.41586462],\n        [ 0.34944195,  0.22418274, -0.1498829 , ..., -0.14773628,\n         -0.20128894, -0.12918273]]], dtype=float32)>"
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "# 方式二\n",
    "model = Sequential([\n",
    "    # 隐藏层1\n",
    "    layers.Dense(256, activation=tf.nn.relu),\n",
    "    # 隐藏层2\n",
    "    layers.Dense(128, activation=tf.nn.relu),\n",
    "    # 隐藏层3\n",
    "    layers.Dense(64, activation=tf.nn.relu),\n",
    "    # 隐藏层\n",
    "    layers.Dense(10, activation=None)\n",
    "])\n",
    "out = model(x)  # 前向计算得到输出\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 优化目标"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 激活函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid\n",
    "也叫Logistic函数，定义为：\n",
    "\n",
    "$Sigmoid(x)\\stackrel{\\mathrm{\\Delta}}{=}{\\frac{1}{1+e^{-x}}}$\n",
    "\n",
    "把$x \\in R$的输入压缩到$x \\in (0,1)$ 区间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tf.Tensor: shape=(10,), dtype=float32, numpy=\narray([0.00247262, 0.00931596, 0.0344452 , 0.11920292, 0.33924365,\n       0.6607564 , 0.880797  , 0.96555483, 0.99068403, 0.9975274 ],\n      dtype=float32)>"
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "source": [
    "x = tf.linspace(-6., 6., 10)\n",
    "out = tf.nn.sigmoid(x)\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReLU\n",
    "$ReLU(x)\\stackrel{\\mathrm{\\Delta}}{=}max(0,x)$\n",
    "\n",
    "x < 0时，返回0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tf.Tensor: shape=(10,), dtype=float32, numpy=\narray([0.      , 0.      , 0.      , 0.      , 0.      , 0.666667,\n       2.      , 3.333334, 4.666667, 6.      ], dtype=float32)>"
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "source": [
    "x = tf.linspace(-6., 6., 10)\n",
    "out = tf.nn.relu(x)\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LeakyReLU\n",
    "$LeakyReLU\\stackrel{\\mathrm{\\Delta}}{=}\\begin{cases}x, x\\geq0,\\\\px, x<0\\end{cases}$\n",
    "\n",
    "p为用户自行设置的某较小数值的超参数，如0.02等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tf.Tensor: shape=(10,), dtype=float32, numpy=\narray([-0.6       , -0.46666667, -0.33333334, -0.2       , -0.06666666,\n        0.666667  ,  2.        ,  3.333334  ,  4.666667  ,  6.        ],\n      dtype=float32)>"
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "source": [
    "x = tf.linspace(-6., 6., 10)\n",
    "out = tf.nn.leaky_relu(x, alpha=0.1)\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tanh\n",
    "$tanh(x) = \\frac{(e^x-e^{-x})}{(e^x+e^{-x})}$\n",
    "\n",
    "= $2 \\cdot sigmoid(2x) -1$\n",
    "\n",
    "将$x \\in R$的输入压缩到$(-1,1)$区间，相当于通过Sigmoid函数缩放平移后实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tf.Tensor: shape=(10,), dtype=float32, numpy=\narray([-0.99998784, -0.99982315, -0.9974579 , -0.9640276 , -0.58278286,\n        0.58278316,  0.9640276 ,  0.99745804,  0.99982315,  0.99998784],\n      dtype=float32)>"
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "source": [
    "x = tf.linspace(-6., 6., 10)\n",
    "out = tf.nn.tanh(x)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python37664bitc7469fbc70d24cd09fc851a175be7ffb",
   "display_name": "Python 3.7.6 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}